<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1" name="viewport" >
    <meta content="I believe there is a whole new range of unexplored applications for Rule Engines (AI/Expert Systems) and Machine Learning; I also believe defining the Business Rules on the BRMS system not only enables knowledge inference from raw data, but most importantly when modeled using the DMN open standard, it helps to shorten the distance between experts and analysts, between developers and end-users, business stakeholders." name="description"> 
    <title>IIBA eXplainable Predictive Decisioning</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css" rel="stylesheet">
    <style>
.blog-header {
  font-family: "Playfair Display", Georgia, "Times New Roman", serif/*rtl:Amiri, Georgia, "Times New Roman", serif*/;
}
    </style>
</head>
<body>	
<header>
  <div class="navbar navbar-dark bg-dark shadow-lg">
    <div class="container">
      <a href="/index.html" class="navbar-brand d-flex align-items-center">
        <strong>matteomortari.com</strong>
      </a>
    </div>
  </div>
</header>

<main><section class="my-2 py-5 container">
	<div class="page-header">
		<h1>IIBA eXplainable Predictive Decisioning</h1>
	</div>

	<p><em>01 December 2020</em></p>

<div class="row justify-content-center text-center">
<div class="col-lg-6">
<div class="ratio ratio-16x9">
	<iframe src="https://www.youtube.com/embed/PyUBEFe1CCc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
</div>
</div>

	<p><div class="sect1">
<h2 id="_why_is_this_customer_high_risk_how_explainable_predictive_decisioning_can_help_us_trust_our_ai">Why Is This Customer 'High Risk': How eXplainable Predictive Decisioning Can Help Us Trust Our AI</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The increased demand for transparent, explainable decision making, that is accurate, consistent and effective, has never been greater. Legislations like GDPR are just a result of increasing concerns about privacy, safety and transparency in general. While AI/ML solutions are great at making sense of high volumes of data, the reasoning process is usually quite opaque, sometimes leaving us baffled as to why it made a particular recommendation.</p>
</div>
<div class="paragraph">
<p>You will learn about the latest research in the field of eXplainable AI (XAI), an approach that combines AI/ML and traditional business rules to better understand the factors that contribute to an automated decision. Presenters will introduce you to the latest standards for representing decision logic, and will demonstrate an XAI solution built from open source components that will show how we can finally answer questions about why an automated decision was made.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_speakers_bio">Speakers Bio</h2>
<div class="sectionbody">
<div class="paragraph">
<p><a href="https://www.linkedin.com/in/matteomortari">Matteo Mortari</a> is a Senior Software Engineer at Red Hat, where he contributes in Drools development and support for the DMN standard. Matteo graduated from Engineering with focus on enterprise systems with a thesis involving rule engines which sparked his interests and influenced his professional career since. He believes there is a whole new range of unexplored applications for Expert Systems (AI) within the Corporate business; additionally, he believes defining the Business Rules on the BRMS system not only enables knowledge inference from raw data but, most importantly, helps to shorten the distance between experts and analysts, between developers and end-users, business stakeholders.</p>
</div>
<div class="paragraph">
<p>Daniele Zonca is the architect of Red Hat Decision Manager and TrustyAI initiative where he contributes to open source projects Drools and Kogito focusing in particular on predictive model runtime support (PMML), ML explainability, runtime tracing and decision monitoring. Before that he led the Big Data development team in one of the major European banks designing and implementing analytical engines.</p>
</div>
</div>
</div></p>

</section>
</main>

<footer class="text-muted py-5">
  <div class="container">
    <p class="float-end mb-1">
      <a href="#">Back to top</a>
    </p>
    <p>&copy; Matteo Mortari. All rights reserved
      <br/><a href="https://www.linkedin.com/in/matteomortari" class="text-reset">LinkedIn</a>
      <br/><a href="https://www.youtube.com/MatteoMortari" class="text-reset">YouTube</a>
      <br/><a href="https://github.com/tarilabs" class="text-reset">Github</a>
      <!-- <br/><a href="https://twitter.com/tari_manga" class="text-reset">Twitter</a> -->
    </p>
  </div>
</footer>

<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4" crossorigin="anonymous"></script>

  </body>
</html>